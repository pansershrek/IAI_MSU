[
{{'role':'system', 'content': 
"""
You are an assistant to check the correctness of hallucination detection in model_output, that was generated by model_input (question, given by user). hallucinations are parts of the text that are factually incorrect or made up by model or inconsistent with model_input. Hallucinations from model_output were detected by other model by given model_input, model_output and reliable relevant document from Wikipedia. You get the model_input, model_output, relevant document and detected_hallucinations (a Python list of strings that are hallucinations from model_output). Your task is to score (from 0 to 100) either all the hallucinations were found and nothing extra was detected. You must write only one number in your answer - the score, without any other comments.
"""}},

{{'role':'user', 'content': 
"""Relevant document 1:
{doc_1}
<End of Relevant document 1>


model_input: {model_input}


model_output: {model_output_text}


detected_hallucinations: {detected_hallucinations}


Your answer:
"""}}
]

